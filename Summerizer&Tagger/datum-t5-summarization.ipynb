{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 22:19:36.185438 10724 file_utils.py:39] PyTorch version 1.4.0 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "import os\n",
    "from flask import Flask, jsonify, request\n",
    "from flask_restful import Api, Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 22:19:57.175183 10724 filelock.py:274] Lock 2140732403048 acquired on C:\\Users\\samar/.cache\\torch\\transformers\\26561bc9e840d8945f475d0d4c4b9df32025eadd79894b867b570cb1d09e67a9.3817cc1260a6b941b17af62b4f2a942b9825f209d8e2eed99e79e96f85f59aab.lock\n",
      "I0816 22:19:57.178174 10724 file_utils.py:748] https://s3.amazonaws.com/models.huggingface.co/bert/t5-small-config.json not found in cache or force_download set to True, downloading to C:\\Users\\samar\\.cache\\torch\\transformers\\tmpodb_gh07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b38467e7b344e13904bca2991d2eb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1197, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 22:19:58.049338 10724 file_utils.py:752] storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-small-config.json in cache at C:\\Users\\samar/.cache\\torch\\transformers\\26561bc9e840d8945f475d0d4c4b9df32025eadd79894b867b570cb1d09e67a9.3817cc1260a6b941b17af62b4f2a942b9825f209d8e2eed99e79e96f85f59aab\n",
      "I0816 22:19:58.054325 10724 file_utils.py:755] creating metadata file for C:\\Users\\samar/.cache\\torch\\transformers\\26561bc9e840d8945f475d0d4c4b9df32025eadd79894b867b570cb1d09e67a9.3817cc1260a6b941b17af62b4f2a942b9825f209d8e2eed99e79e96f85f59aab\n",
      "I0816 22:19:58.060310 10724 filelock.py:318] Lock 2140732403048 released on C:\\Users\\samar/.cache\\torch\\transformers\\26561bc9e840d8945f475d0d4c4b9df32025eadd79894b867b570cb1d09e67a9.3817cc1260a6b941b17af62b4f2a942b9825f209d8e2eed99e79e96f85f59aab.lock\n",
      "I0816 22:19:58.062303 10724 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-small-config.json from cache at C:\\Users\\samar/.cache\\torch\\transformers\\26561bc9e840d8945f475d0d4c4b9df32025eadd79894b867b570cb1d09e67a9.3817cc1260a6b941b17af62b4f2a942b9825f209d8e2eed99e79e96f85f59aab\n",
      "I0816 22:19:58.064297 10724 configuration_utils.py:300] Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "I0816 22:19:58.904320 10724 filelock.py:274] Lock 2140732403048 acquired on C:\\Users\\samar/.cache\\torch\\transformers\\9b662cba85524bef76fff5eb77d767407ac36f3fe492869331c011efd2b3a082.388aab7f5c8ed273dc71eb98334d76a3caf1b3280b476c1c77fba861c65445f3.lock\n",
      "I0816 22:19:58.907285 10724 file_utils.py:748] https://cdn.huggingface.co/t5-small-pytorch_model.bin not found in cache or force_download set to True, downloading to C:\\Users\\samar\\.cache\\torch\\transformers\\tmp_zxuuicl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684c4e02f6a84a2fa08bb3b22d0d7cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=242065649, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 22:21:00.450437 10724 file_utils.py:752] storing https://cdn.huggingface.co/t5-small-pytorch_model.bin in cache at C:\\Users\\samar/.cache\\torch\\transformers\\9b662cba85524bef76fff5eb77d767407ac36f3fe492869331c011efd2b3a082.388aab7f5c8ed273dc71eb98334d76a3caf1b3280b476c1c77fba861c65445f3\n",
      "I0816 22:21:00.453430 10724 file_utils.py:755] creating metadata file for C:\\Users\\samar/.cache\\torch\\transformers\\9b662cba85524bef76fff5eb77d767407ac36f3fe492869331c011efd2b3a082.388aab7f5c8ed273dc71eb98334d76a3caf1b3280b476c1c77fba861c65445f3\n",
      "I0816 22:21:00.456424 10724 filelock.py:318] Lock 2140732403048 released on C:\\Users\\samar/.cache\\torch\\transformers\\9b662cba85524bef76fff5eb77d767407ac36f3fe492869331c011efd2b3a082.388aab7f5c8ed273dc71eb98334d76a3caf1b3280b476c1c77fba861c65445f3.lock\n",
      "I0816 22:21:00.458416 10724 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/t5-small-pytorch_model.bin from cache at C:\\Users\\samar/.cache\\torch\\transformers\\9b662cba85524bef76fff5eb77d767407ac36f3fe492869331c011efd2b3a082.388aab7f5c8ed273dc71eb98334d76a3caf1b3280b476c1c77fba861c65445f3\n",
      "I0816 22:21:02.028221 10724 modeling_utils.py:765] All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "W0816 22:21:02.030215 10724 modeling_utils.py:768] Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "I0816 22:21:02.865272 10724 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at C:\\Users\\samar/.cache\\torch\\transformers\\68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "5416\n"
     ]
    }
   ],
   "source": [
    "# INSERT TEXT HERE\n",
    "\n",
    "text =\"\"\"\n",
    "coronavirus vaccine developed by the University of Oxford appears safe and triggers an immune response. Trials involving 1,077 people showed the injection led to them making antibodies and T-cells that can fight coronavirus. The findings are hugely promising, but it is still too soon to know if this is enough to offer protection and larger trials are under way.\n",
    "The UK has already ordered 100 million doses of the vaccine. How does the vaccine work?\n",
    "The vaccine - called ChAdOx1 nCoV-19 - is being developed at unprecedented speed. It is made from a genetically engineered virus that causes the common cold in chimpanzees.\n",
    "It has been heavily modified, first so it cannot cause infections in people and also to make it \"look\" more like coronavirus. Scientists did this by transferring the genetic instructions for the coronavirus's \"spike protein\" - the crucial tool it uses to invade our cells - to the vaccine they were developing. This means the vaccine resembles the coronavirus and the immune system can learn how to attack it. What are antibodies and T-cells? Much of the focus on coronavirus so far has been about antibodies, but these are only one part of our immune defence. Antibodies are small proteins made by the immune system that stick onto the surface of viruses. Neutralising antibodies can disable the coronavirus. T-cells, a type of white blood cell, help co-ordinate the immune system and are able to spot which of the body's cells have been infected and destroy them. Nearly all effective vaccines induce both an antibody and a T-cell response. Sample from patients are analysed as part of the trial.\n",
    "\n",
    "Levels of T-cells peaked 14 days after vaccination and antibody levels peaked after 28 days. The study has not run for long enough to understand how long they may last, the study in the Lancet showed. Prof Andrew Pollard, from the Oxford research group told the BBC: \"We're really pleased with the results published today as we're seeing both neutralising antibodies and T-cells.\" They're extremely promising and we believe the type of response that may be associated with protection. \"But the key question everyone wants to know is does the vaccine work, does it offer protection and we're in a waiting game.\"\n",
    "\n",
    "The study showed 90% of people developed neutralising antibodies after one dose. Only ten people were given two doses and all of them produced neutralising antibodies. \n",
    "\"We don't know the level needed for protection, but we can maximise responses with a second dose,\" Prof Pollard told the BBC. Is it safe? Yes, but there are side-effects.\n",
    "\n",
    "There were no dangerous side-effects from taking the vaccine, however, 70% of people on the trial developed either fever or headache. The researchers say this could be managed with paracetamol. Prof Sarah Gilbert, from the University of Oxford, UK, says: \"There is still much work to be done before we can confirm if our vaccine will help manage the Covid-19 pandemic, but these early results hold promise.\"\n",
    "\n",
    "What are the next steps in the trial? The results so far are promising, but their main purpose is to ensure the vaccine is safe enough to give to people. The study cannot show whether the vaccine can either prevent people from becoming ill or even lessen their symptoms of Covid-19. More than 10,000 people will take part in the next stage of the trials in the UK.\n",
    "\n",
    "However, the trial has also been expanded to other countries because levels of coronavirus are low in the UK, making it hard to know if the vaccine is effective.\n",
    "There will be a large trial involving 30,000 people in the US as well 2,000 in South Africa and 5,000 in Brazil. There are also calls to perform \"challenge trials\" in which vaccinated people are deliberately infected with coronavirus. However, there are ethical concerns due to a lack of treatments. When will I get a vaccine? It is possible a coronavirus vaccine will be proven effective before the end of the year, however, it will not be widely available. Health and care workers will be prioritised as will people who are deemed at high risk from Covid-19 due to their age or medical conditions. However, widespread vaccination is likely to be, at the earliest, next year even if everything goes to plan. Boris Johnson said: \"Obviously I'm hopeful, I've got my fingers crossed, but to say I'm 100% confident we'll get a vaccine this year, or indeed next year, is, alas, just an exaggeration. \"We're not there yet.\"\n",
    "What progress is being made with other vaccines?\n",
    "The Oxford vaccine is not the first to reach this stage, with groups in the US and China also publishing similar results. The US company Moderna was first out of the blocks and its vaccine can produce neutralising antibodies. They are injecting coronavirus RNA (its genetic code), which then starts making viral proteins in order to trigger an immune response. The companies BioNtech and Pfizer have also had positive results using their RNA vaccine. A technique similar to the Oxford one, developed in China, also seems promising. However, all these approaches are at the absolute boundary of science and have not been proven to work before. More traditional methods of vaccine development are also being investigated. The company Valneva is taking the whole coronavirus, inactivating it and then inject it. In total there are 23 coronavirus vaccines in clinical trials around the world and another 140 in early stage development.\n",
    "\"\"\"\n",
    "print(device)\n",
    "print(len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us vaccine developed by the University of Oxford appears safe and triggers an immune response. Trials involving 1,077 people showed the injection led to them making antibodies and T-cells that can fight coronavirus. The findings are hugely promising, but it is still too soon to know if this is enough to offer protection and larger trials are under way.\\nThe UK has already ordered 100 million doses of the vaccine. How does the vaccine work?\\nThe vaccine - called ChAdOx1 nCoV-19 - is being developed at unprecedented speed. It is made from a genetically engineered virus that causes the common cold in chimpanzees.\\nIt has been heavily modified, first so it cannot cause infections in people and also to make it \"look\" more like coronavirus. Scientists did this by transferring the genetic instructions for the coronavirus\\'s \"spike protein\" - the crucial tool it uses to invade our cells - to the vaccine they were developing. This means the vaccine resembles the coronavirus and the immune system can learn how to attack it. What are antibodies and T-cells? Much of the focus on coronavirus so far has been about antibodies, but these are only one part of our immune defence. Antibodies are small proteins made by the immune system that stick onto the surface of viruses. Neutralising antibodies can disable the coronavirus. T-cells, a type of white blood cell, help co-ordinate the immune system and are able to spot which of the body\\'s cells have been infected and destroy them. Nearly all effective vaccines induce both an antibody and a T-cell response. Sample from patients are analysed as part of the trial.\\n\\nLevels of T-cells peaked 14 days after vaccination and antibody levels peaked after 28 days. The study has not run for long enough to understand how long they may last, the study in the Lancet showed. Prof Andrew Pollard, from the Oxford research group told the BBC: \"We\\'re really pleased with the results published today as we\\'re seeing both neutralising antibodies and T-cells.\" They\\'re extrem'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[10:2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 22:23:23.776479 10724 _internal.py:122]  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "%tb\n",
    "app = Flask(__name__)\n",
    "api = Api(app)\n",
    "\n",
    "class SendSummary(Resource):\n",
    "    @staticmethod\n",
    "    def post():\n",
    "#         text = \"coronavirus vaccine developed by the University of Oxford appears safe and triggers an immune response.\\n\\nTrials involving 1,077 people showed the injection led to them making antibodies and T-cells that can fight coronavirus.\\n\\nThe findings are hugely promising, but it is still too soon to know if this is enough to offer protection and larger trials are under way.\\n\\nThe UK has already ordered 100 million doses of the vaccine.\\n\\nHow does the vaccine work?\\nThe vaccine - called ChAdOx1 nCoV-19 - is being developed at unprecedented speed.\\n\\nIt is made from a genetically engineered virus that causes the common cold in chimpanzees.\\n\\nIt has been heavily modified, first so it cannot cause infections in people and also to make it look more like coronavirus.\\n\\nScientists did this by transferring the genetic instructions for the coronavirus\\'s spike protein - the crucial tool it uses to invade our cells - to the vaccine they were developing.\\n\\nThis means the vaccine resembles the coronavirus and the immune system can learn how to attack it.\\n\\nWhat are antibodies and T-cells?\\nMuch of the focus on coronavirus so far has been about antibodies, but these are only one part of our immune defence.\\n\\nAntibodies are small proteins made by the immune system that stick onto the surface of viruses.\\n\\nNeutralising antibodies can disable the coronavirus.\\n\\nT-cells, a type of white blood cell, help co-ordinate the immune system and are able to spot which of the body\\'s cells have been infected and destroy them.\\n\\nNearly all effective vaccines induce both an antibody and a T-cell response.\\n\\nImage copyrightOXFORD UNIVERSITY\\nImage caption\\nSample from patients are analysed as part of the trial.\\nLevels of T-cells peaked 14 days after vaccination and antibody levels peaked after 28 days.\"\n",
    "        \n",
    "        posted_data = request.get_json()\n",
    "        text = posted_data[\"req\"].strip().replace(\"\\n\",\"\")\n",
    "        text_toks = text.split(\" \")\n",
    "        l = len(text_toks)\n",
    "        preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "        t5_prepared_Text = \"summarize: \"+ preprocess_text\n",
    "        print(t5_prepared_Text)\n",
    "        print(\"\\n\")\n",
    "        tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        model.to(device)\n",
    "        \n",
    "        summary_ids = model.generate(tokenized_text,\n",
    "                                            num_beams=5,\n",
    "                                            no_repeat_ngram_size=2,\n",
    "                                            min_length= abs(int(l * 0.3)),\n",
    "                                            max_length= abs(int(l * 0.5)),\n",
    "                                            early_stopping=True)\n",
    "        \n",
    "        output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        output_texts = output.split('.')\n",
    "        response = \"\"\n",
    "        \n",
    "        for x in range(len(output_texts)-1):\n",
    "            response += ('-> ' + output_texts[x].strip()) + \"\\n\"\n",
    "        \n",
    "        print (\"Summarized text: \\n\" + response)\n",
    "        \n",
    "        return jsonify({\n",
    "            'resp': response\n",
    "        })\n",
    "\n",
    "api.add_resource(SendSummary, '/resp')\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "# t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "# # print (\"original text preprocessed: \\n\", preprocess_text)\n",
    "# txt_length = len(preprocess_text)\n",
    "# print(txt_length)\n",
    "# max_length_output = (int)(np.floor(txt_length * 0.2))\n",
    "# print(max_length_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "# text_toks = text.split(\" \")\n",
    "# l = len(text_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # summmarize \n",
    "# model.to(device)\n",
    "# summary_ids = model.generate(tokenized_text,\n",
    "#                                     num_beams=5,\n",
    "#                                     no_repeat_ngram_size=2,\n",
    "#                                     min_length= int(l * 0.7),\n",
    "#                                     max_length= int(l * 0.8),\n",
    "#                                     early_stopping=False)\n",
    "\n",
    "# output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
